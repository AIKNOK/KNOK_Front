import React, { useState, useEffect, useRef } from "react";
import { useNavigate } from "react-router-dom";
import { Button } from "../../shared/Button";
import { usePostureTracking } from "../../../hooks/usePostureTracking";
import { encodeWAV } from "../../../utils/encodeWAV";

interface Question {
  id: string;
  text: string;
  type: "technical" | "behavioral";
  difficulty: "easy" | "medium" | "hard";
}

const API_BASE = import.meta.env.VITE_API_BASE_URL;
const MAX_ANSWER_DURATION = 90; // ì´ˆ

export const InterviewSession = () => {
  /*=============================================*/

  const navigate = useNavigate();
  const videoRef = useRef<HTMLVideoElement>(null);
  const streamRef = useRef<MediaStream | null>(null);

  const convertFloat32ToInt16 = (buffer: Float32Array): Uint8Array => {
    const result = new Int16Array(buffer.length);
    for (let i = 0; i < buffer.length; i++) {
      const s = Math.max(-1, Math.min(1, buffer[i]));
      result[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }
    return new Uint8Array(result.buffer);
  };

  // í¬ì¦ˆ ì¶”ì  í›… (videoRef ì „ë‹¬ â†’ ë‚´ë¶€ì—ì„œ ì–¼êµ´/ìì„¸ ì¶”ì )
  const badPostureCountRef = usePostureTracking(videoRef);

  // ë§ˆì´í¬ ìƒíƒœ: ì—°ê²° ì—¬ë¶€, ë³¼ë¥¨ ë ˆë²¨
  const [micConnected, setMicConnected] = useState(false);
  const [micLevel, setMicLevel] = useState(0);

  // ë©´ì ‘ ì§„í–‰ ìƒíƒœ
  const [isInterviewActive, setIsInterviewActive] = useState(false);
  const [questions, setQuestions] = useState<Question[]>([]);
  const [qIdx, setQIdx] = useState(0);
  const [recordTime, setRecordTime] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState(""); // í”„ë¡ íŠ¸ í…ŒìŠ¤íŠ¸ìš©(ì‹¤ì œ STTëŠ” ë°±ì—”ë“œ)

  // ë…¹ìŒ ê´€ë ¨ refs
  const wsRef = useRef<WebSocket | null>(null);
  const audioChunksRef = useRef<Float32Array[]>([]);
  const audioContextRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const recordTimerRef = useRef<number | null>(null);

  const [isLoading, setIsLoading] = useState(false);

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 1) ë§ˆìš´íŠ¸ ì‹œ: ì¹´ë©”ë¼ + ë§ˆì´í¬ ì—°ê²° & ë³¼ë¥¨ ì‹œê°í™”
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  useEffect(() => {
    let analyser: AnalyserNode;
    let animId: number;
    let mediaStream: MediaStream | null = null;

    const setupMedia = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: true, // í•„ìš” ì—†ìœ¼ë©´ false
          audio: {
            channelCount: 1,
            sampleRate: 16000,
            sampleSize: 16,
          },
        });
        // ë¹„ë””ì˜¤ í™”ë©´ì— ìŠ¤íŠ¸ë¦¼ ì—°ê²°
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
        }
        streamRef.current = stream;
        mediaStream = stream;
        setMicConnected(true);
        console.log("ğŸ¤ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¤€ë¹„ ì™„ë£Œ");

        // AudioContext / webkitAudioContext íƒ€ì… ë‹¨ì–¸
        const AudioCtxClass =
          (window as any).AudioContext || (window as any).webkitAudioContext;
        if (!AudioCtxClass) {
          alert("ì´ ë¸Œë¼ìš°ì €ëŠ” AudioContextë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
          return;
        }

        // ìƒ˜í”Œë ˆì´íŠ¸ë¥¼ 44100ìœ¼ë¡œ ê³ ì • (encodeWAVì™€ ì¼ì¹˜ì‹œí‚´)
        const audioCtx = new AudioCtxClass({ sampleRate: 16000 });
        audioContextRef.current = audioCtx;

        // Chromeì—ì„œ HTTPSê°€ ì•„ë‹Œ ê²½ìš° AudioContextê°€ suspendedê°€ ë˜ë¯€ë¡œ resume
        if (audioCtx.state === "suspended") {
          console.log("ğŸ§ AudioContext ì´ˆê¸° ìƒíƒœ:", audioCtx.state);
          await audioCtx.resume();
          console.log("â–¶ AudioContext resumed (ë§ˆì´í¬ ë³¼ë¥¨ ì‹œê°í™” ì‹œì‘)");
        }

        // ë³¼ë¥¨ ì‹œê°í™”ë¥¼ ìœ„í•œ AnalyserNode
        const source = audioCtx.createMediaStreamSource(stream);
        analyser = audioCtx.createAnalyser();
        analyser.fftSize = 256;
        source.connect(analyser);

        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        const draw = () => {
          analyser.getByteFrequencyData(dataArray);
          const avg =
            dataArray.reduce((sum, v) => sum + v, 0) / dataArray.length;
          setMicLevel(Math.min(100, (avg / 255) * 100));
          animId = requestAnimationFrame(draw);
        };
        draw();
      } catch (err) {
        console.error("getUserMedia error:", err);
        setMicConnected(false);
        // í™˜ê²½ ì ê²€ í˜ì´ì§€ë¡œ ê°•ì œ ì´ë™
        navigate("/interview/check-environment");
      }
    };

    setupMedia();

    return () => {
      // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
      cancelAnimationFrame(animId);
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      if (mediaStream) {
        mediaStream.getTracks().forEach((t) => t.stop());
      }
    };
  }, [navigate]);

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 2) "AI ë©´ì ‘ ì‹œì‘í•˜ê¸°" ë²„íŠ¼ í´ë¦­ â†’ ì§ˆë¬¸ ìƒì„± â†’ ìƒíƒœ ì„¸íŒ… (isInterviewActive=true)
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const onStart = async () => {
    const token =
      localStorage.getItem("id_token") || localStorage.getItem("access_token");
    if (!token) {
      alert("ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.");
      return;
    }
    setIsLoading(true);

    try {
      const res = await fetch(`${API_BASE}/generate-resume-questions/`, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${token}`,
          "Content-Type": "application/json",
        },
      });
      if (!res.ok) {
        throw new Error(await res.text());
      }
      const { questions: qs }: { questions: string[] } = await res.json();

      // Question íƒ€ì…ìœ¼ë¡œ ë³€í™˜
      const mapped: Question[] = qs.map((text, idx) => ({
        id: `${idx + 1}`,
        text,
        type: "behavioral",
        difficulty: "medium",
      }));
      setQuestions(mapped);
      setQIdx(0);
      setIsInterviewActive(true);
      // â†’ ì´ì œ useEffectì—ì„œ ë…¹ìŒì´ ìë™ìœ¼ë¡œ ì‹œì‘ëœë‹¤.
    } catch (err) {
      console.error("ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨:", err);
      alert("ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨");
    } finally {
      setIsLoading(false);
    }
  };

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 3) isInterviewActive ë˜ëŠ” qIdx ë³€ê²½ ì‹œ â†’ ë…¹ìŒ ìë™ ì‹œì‘
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  useEffect(() => {
    if (!isInterviewActive) return;
    console.log("â–¶ ë©´ì ‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. í˜„ì¬ ì§ˆë¬¸ ì¸ë±ìŠ¤:", qIdx);
    startRecording(); // âœ… streamRefëŠ” ì´ë¯¸ ì¤€ë¹„ëœ ìƒíƒœ
  }, [isInterviewActive, qIdx]);

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 4) ë…¹ìŒ ì‹œì‘ â†’ AudioContext ìƒì„± â†’ ScriptProcessorNodeë¡œ ìƒ˜í”Œ ìˆ˜ì§‘
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const startRecording = async () => {
    if (!questions[qIdx] || !streamRef.current) return;

    const token =
      localStorage.getItem("id_token") || localStorage.getItem("access_token");
    const email = localStorage.getItem("user_email") || "anonymous";
    const questionId = questions[qIdx].id;

    const ws = new WebSocket(
      `ws://localhost:8001/ws/transcribe?email=${email}&question_id=${questionId}&token=${token}`
    );
    wsRef.current = ws;

    ws.onopen = async () => {
      console.log("âœ… WebSocket ì—°ê²° ì„±ê³µ");
      const dummyAudio = new Uint8Array(16000 * 2); // ì•½ 100ms ë¶„ëŸ‰ (16kHz, 16bit PCM)
      console.log("ğŸŸ¡ ì´ˆê¸° dummy ì˜¤ë””ì˜¤ ì „ì†¡:", dummyAudio.length, "bytes");

      // âœ… AudioContext ì—°ê²° (ì´ì œ streamRefê°€ ì™„ì „íˆ ì¤€ë¹„ë¨)
      const AudioContextClass =
        window.AudioContext || (window as any).webkitAudioContext;
      const audioCtx = new AudioContextClass({ sampleRate: 16000 });
      console.log("ğŸ§ AudioContext ìƒ˜í”Œë ˆì´íŠ¸:", audioCtx.sampleRate);
      audioContextRef.current = audioCtx;
      await audioCtx.resume();

      const source = audioCtx.createMediaStreamSource(streamRef.current!);
      const processor = audioCtx.createScriptProcessor(4096, 1, 1);
      processorRef.current = processor;

      processor.onaudioprocess = (e) => {
        console.log("ğŸ§ onaudioprocess ì‹¤í–‰");
        const floatData = e.inputBuffer.getChannelData(0);
        const pcmData = convertFloat32ToInt16(floatData);
        audioChunksRef.current.push(new Float32Array(floatData)); // âœ… ë…¹ìŒ ì €ì¥ìš©
        if (ws.readyState === WebSocket.OPEN) {
          ws.send(pcmData);
          console.log("ğŸ™ï¸ ì˜¤ë””ì˜¤ ì „ì†¡:", pcmData.length, "bytes");
        }
      };

      source.connect(processor);
      processor.connect(audioCtx.destination);

      // âœ… íƒ€ì´ë¨¸ ì‹œì‘
      setRecordTime(0);
      setIsRecording(true);
      recordTimerRef.current = window.setInterval(() => {
        setRecordTime((prev) => {
          if (prev + 1 >= MAX_ANSWER_DURATION) {
            (async () => await stopRecording())();
            return prev;
          }
          return prev + 1;
        });
      }, 1000);
    };

    ws.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.transcript) {
        setTranscript((prev) => prev + data.transcript + "\n");
      }
      if (data.status === "done") {
        console.log("âœ… ë°±ì—”ë“œ ì—…ë¡œë“œ ì™„ë£Œ");
        ws.close();
      }
    };

    ws.onerror = (e) => {
      console.error("âŒ WebSocket ì˜¤ë¥˜", e);
    };

    ws.onclose = () => {
      console.log("ğŸ”Œ WebSocket ì¢…ë£Œ");
    };
  };

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // 5) ë…¹ìŒ ì¤‘ì§€ â†’ ìƒ˜í”Œ í•©ì³ì„œ WAVë¡œ ë³€í™˜ â†’ ì„œë²„ ì—…ë¡œë“œ â†’ ì§ˆë¬¸ ë³€ê²½ or ë©´ì ‘ ì¢…ë£Œ
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  const stopRecording = async () => {
    console.log("â–¶ stopRecording í˜¸ì¶œë¨");
    setIsRecording(false);

    if (recordTimerRef.current) {
      clearInterval(recordTimerRef.current);
      console.log("â–¶ ë…¹ìŒ íƒ€ì´ë¨¸ ì •ì§€");
    }

    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      const endSignal = new TextEncoder().encode("END"); // <-- ì¤‘ìš”!
      wsRef.current.send(endSignal);
      console.log("ğŸ“¤ END ì‹ í˜¸ ì „ì†¡ (ë°”ì´íŠ¸)");

      await new Promise((res) => setTimeout(res, 300));
      wsRef.current.close();
    }

    processorRef.current?.disconnect();
    audioContextRef.current?.close();
    streamRef.current?.getTracks().forEach((t) => t.stop());

    const token =
      localStorage.getItem("id_token") || localStorage.getItem("access_token");
    const email = localStorage.getItem("user_email") || "anonymous";
    const currentQ = questions[qIdx - 1] ||
      questions[qIdx] || { id: "unknown" };
    const questionId = currentQ.id;

    // Float32Array[] â†’ Float32Array
    const floatArray = audioChunksRef.current.reduce((acc, cur) => {
      const tmp = new Float32Array(acc.length + cur.length);
      tmp.set(acc, 0);
      tmp.set(cur, acc.length);
      return tmp;
    }, new Float32Array());

    const wavBlob = encodeWAV(floatArray, 16000);
    const wavFile = new File([wavBlob], "answer.wav", { type: "audio/wav" });
    const textBlob = new Blob([transcript], { type: "text/plain" });
    const textFile = new File([textBlob], "transcript.txt", {
      type: "text/plain",
    });

    const formData = new FormData();
    formData.append("audio", wavFile);
    formData.append("transcript", textFile);
    formData.append("email", email);
    formData.append("question_id", questionId);

    try {
      await fetch(`${API_BASE}/audio/upload/`, {
        method: "POST",
        headers: {
          Authorization: `Bearer ${token}`,
        },
        body: formData,
      });
      console.log("âœ… S3 ì—…ë¡œë“œ ì™„ë£Œ");
    } catch (err) {
      console.error("âŒ ì—…ë¡œë“œ ì‹¤íŒ¨", err);
    }

    if (qIdx < questions.length - 1) {
      setQIdx((prev) => prev + 1);
      setTranscript("");
      audioChunksRef.current = [];
    } else {
      setIsInterviewActive(false);
      navigate("/interview/feedback");
    }
  };

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  //  ìˆ˜ë™ìœ¼ë¡œ â€œë‹¤ìŒ ì§ˆë¬¸â€ ë˜ëŠ” â€œë©´ì ‘ ì¢…ë£Œâ€ ë²„íŠ¼ í´ë¦­ ì‹œ
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const handleNext = async () => {
    console.log("â–¶ handleNext() í˜¸ì¶œë¨, isRecording:", isRecording);
    if (isRecording) {
      console.log("â–¶ stopRecording() í˜¸ì¶œ ì „");
      await stopRecording();
      console.log("â–¶ stopRecording() í˜¸ì¶œ ì™„ë£Œ");
    }
  };

  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  //  UI ë Œë”ë§
  // â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  return (
    <div className="pt-[92px] relative min-h-screen bg-gray-900 text-white">
      <div className="max-w-7xl mx-auto px-4 py-8 grid grid-cols-1 md:grid-cols-3 gap-8">
        {/* â”Œ ë¹„ë””ì˜¤ + ìì„¸ ì˜ì—­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */}
        <div className="md:col-span-2">
          <div className="relative aspect-video bg-black rounded-lg overflow-hidden">
            <video
              ref={videoRef}
              autoPlay
              muted
              playsInline
              className="w-full h-full object-cover"
            />
            {/* ë§ˆì´í¬ ì—°ê²° ìƒíƒœ & ë³¼ë¥¨ ê²Œì´ì§€ */}
            <div className="absolute top-4 left-4 flex flex-col items-start space-y-2 bg-black bg-opacity-50 px-3 py-2 rounded-lg">
              <div>
                <span className="text-xs mr-2">ë§ˆì´í¬ ìƒíƒœ:</span>
                <span
                  className={micConnected ? "text-green-400" : "text-red-400"}
                >
                  {micConnected ? "ì—°ê²°ë¨" : "ë¯¸ì—°ê²°"}
                </span>
              </div>
              <div className="w-32 h-2 bg-gray-600 rounded overflow-hidden">
                <div
                  className="h-full bg-green-400"
                  style={{ width: `${micLevel}%` }}
                />
              </div>
            </div>
          </div>
        </div>

        {/* â”Œ ì§ˆë¬¸ & ì»¨íŠ¸ë¡¤ ì˜ì—­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */}
        <div className="space-y-6">
          {!isInterviewActive ? (
            // ë©´ì ‘ ì‹œì‘ ì „ í™”ë©´
            <div className="bg-gray-800 p-6 rounded-lg">
              <h2 className="text-xl font-semibold mb-4">ë©´ì ‘ ì¤€ë¹„</h2>
              <p className="text-gray-400 mb-6">
                ì´ë ¥ì„œ ê¸°ë°˜ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ë…¹ìŒì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
              </p>
              <Button
                onClick={onStart}
                className="w-full"
                size="lg"
                disabled={isLoading || !micConnected}
                isLoading={isLoading}
              >
                AI ë©´ì ‘ ì‹œì‘í•˜ê¸°
              </Button>
            </div>
          ) : (
            // ë©´ì ‘ ì¤‘ í™”ë©´
            <div className="bg-gray-800 p-6 rounded-lg">
              <div className="flex justify-between items-center mb-4">
                <h3 className="text-lg font-medium">í˜„ì¬ ì§ˆë¬¸</h3>
                <span className="text-sm text-gray-400">
                  {qIdx + 1}/{questions.length}
                </span>
              </div>
              <p className="text-gray-300">{questions[qIdx]?.text}</p>
              <p className="mt-4 text-sm text-gray-400">
                ë‚¨ì€ ë‹µë³€ ì‹œê°„: {MAX_ANSWER_DURATION - recordTime}ì´ˆ
              </p>
              <Button
                variant="outline"
                className="w-full mt-4"
                onClick={handleNext}
                disabled={isLoading}
              >
                {qIdx < questions.length - 1 ? "ë‹¤ìŒ ì§ˆë¬¸" : "ë©´ì ‘ ì¢…ë£Œ"}
              </Button>
            </div>
          )}
        </div>
      </div>

      {/* â”Œ ë¡œë”© ëª¨ë‹¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */}
      {isLoading && (
        <div className="fixed inset-0 bg-black/50 flex items-center justify-center z-50">
          <div className="bg-white rounded-lg p-8 text-center max-w-xs mx-4 space-y-4">
            <h3 className="text-gray-900 text-lg font-semibold">ì²˜ë¦¬ ì¤‘...</h3>
            <svg
              className="mx-auto w-12 h-12 animate-spin text-primary"
              viewBox="0 0 24 24"
            >
              <circle
                className="opacity-25"
                cx="12"
                cy="12"
                r="10"
                stroke="currentColor"
                strokeWidth="4"
              />
              <path
                className="opacity-75"
                fill="currentColor"
                d="M4 12a8 8 0 018-8v8H4z"
              />
            </svg>
          </div>
        </div>
      )}
    </div>
  );
};
