// src/hooks/usePostureTracking.ts
import { useEffect, useRef } from 'react';
import { Pose } from '@mediapipe/pose';
import { FaceMesh, NormalizedLandmark, NormalizedLandmarkList } from '@mediapipe/face_mesh';

export function usePostureTracking(videoRef: React.RefObject<HTMLVideoElement>) {
  const badPostureCountRef = useRef(0);
  let startBadTime: number | null = null;

  useEffect(() => {
    if (!videoRef.current) return;

    const pose = new Pose({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`,
    });

    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`,
    });

    pose.setOptions({
      modelComplexity: 1,
      smoothLandmarks: true,
      enableSegmentation: false,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    faceMesh.setOptions({
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5,
    });

    // ðŸ‘‡ ì–¼êµ´ ëžœë“œë§ˆí¬ë¥¼ ì €ìž¥í•  ë³€ìˆ˜ (ì •í™•í•œ íƒ€ìž… ëª…ì‹œ)
    let latestFaceLandmarks: NormalizedLandmark[] | null = null;

    // ì–¼êµ´ ê²°ê³¼ ë°›ê¸°
    faceMesh.onResults((results) => {
      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        latestFaceLandmarks = results.multiFaceLandmarks[0];
      } else {
        latestFaceLandmarks = null;
      }
    });

    // ìžì„¸ ê²°ê³¼ ë°›ê¸°
    pose.onResults((results) => {
      const poseLandmarks = results.poseLandmarks;
      if (!poseLandmarks) return;

      const lShoulder = poseLandmarks[11];
      const rShoulder = poseLandmarks[12];
      const nose = poseLandmarks[0];
      const lEar = poseLandmarks[7];
      const rEar = poseLandmarks[8];

      // ì–´ê¹¨ ê¸°ìš¸ê¸°
      const dx = lShoulder.x - rShoulder.x;
      const dy = lShoulder.y - rShoulder.y;
      const shoulderAngle = Math.atan2(dy, dx) * (180 / Math.PI);

      // ê³ ê°œ ìˆ™ìž„
      const avgShoulderY = (lShoulder.y + rShoulder.y) / 2;
      const headDown = nose.y > avgShoulderY + 0.1;

      // ê·€ ê¸°ìš¸ê¸°
      const earAngle = Math.atan2(lEar.y - rEar.y, lEar.x - rEar.x) * (180 / Math.PI);

      // ì‹œì„  ííŠ¸ëŸ¬ì§ íŒë‹¨
      let gazeOff = false;
      if (latestFaceLandmarks) {
        const leftIris = latestFaceLandmarks[468];
        const leftEyeLeft = latestFaceLandmarks[33];
        const leftEyeRight = latestFaceLandmarks[133];

        const eyeRange = leftEyeRight.x - leftEyeLeft.x;
        const irisPos = eyeRange > 0
          ? (leftIris.x - leftEyeLeft.x) / eyeRange
          : 0.5;

        if (irisPos < 0.35 || irisPos > 0.65) {
          gazeOff = true;
        }
      }

      const isBad =
        Math.abs(shoulderAngle) > 10 ||
        Math.abs(earAngle) > 10 ||
        headDown ||
        gazeOff;

      if (isBad) {
        if (!startBadTime) {
          startBadTime = Date.now();
        } else if (Date.now() - startBadTime > 3000) {
          badPostureCountRef.current++;
          console.warn('âš ï¸ ìžì„¸ ë‚˜ì¨ count ì¦ê°€ â†’', badPostureCountRef.current);
          startBadTime = null;
        }
      } else {
        startBadTime = null;
      }
    });

    // 3ì´ˆë§ˆë‹¤ ë¶„ì„
    const analyze = async () => {
      const video = videoRef.current;
      if (!video) return;

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d');
      if (!ctx) return;
      ctx.drawImage(video, 0, 0);

      await faceMesh.send({ image: canvas });
      await pose.send({ image: canvas });
    };

    const intervalId = setInterval(analyze, 3000);

    return () => {
      clearInterval(intervalId);
    };
  }, [videoRef]);

  return badPostureCountRef;
}